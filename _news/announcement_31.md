---
layout: post
date: 2024-12-18 15:59:00-0400
inline: true
related_posts: false
---
We have released UniMed, a fully-open-source and large-scale multi-modal medical dataset for advancing Constrastive Medical VLM pretraining. Building upon UniMed, we train UniMed-CLIP, a family of strong medical Vision-Language models. Dataset, training-codes, pretrained models and demos <a href="https://github.com/mbzuai-oryx/UniMed-CLIP">are available here</a>.
